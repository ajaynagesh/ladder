{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!export FUEL_DATA_PATH=\"/work/ajaynagesh/LadderNetworks/ladder/data\"\n",
    "# note: this is not setting the environ variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys,os,os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['FUEL_DATA_PATH']=\"/work/ajaynagesh/LadderNetworks/ladder/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurray! The above is working ... \n",
    "see : https://stackoverflow.com/questions/37890898/how-to-set-env-variable-in-jupyter-notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla P4 (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "from fuel.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments with the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_class = MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??dataset_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_mnist = dataset_class(['train'])\n",
    "test_mnist = dataset_class(['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print( train_mnist.num_examples)\n",
    "print( test_mnist.num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'features': (u'batch', u'channel', u'height', u'width'),\n",
       " u'targets': (u'batch', u'index')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mnist.axis_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ..., \n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ..., \n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ..., \n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        ..., \n",
       "        [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ..., \n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ..., \n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ..., \n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]]], dtype=float32), array([[5],\n",
       "        [0],\n",
       "        [4],\n",
       "        ..., \n",
       "        [5],\n",
       "        [6],\n",
       "        [8]], dtype=uint8))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mnist.data_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments by loading the blocks module of ladder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from run_emboot import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get the logger output in IPython\n",
    "\n",
    "https://stackoverflow.com/questions/18786912/get-output-from-the-logging-module-in-ipython-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the params from the saved params from the trained runs\n",
    "\n",
    "With the following set of cmds I am able to load the saved params of a trained run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cli_params = dict()\n",
    "cli_params['load_from'] = \"/work/ajaynagesh/LadderNetworks/ladder/results/emboot_100_full0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cli_params['data_type'] = 'test'\n",
    "cli_params['no_load'] = 'g_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the params and set up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p, loaded = load_and_log_params(cli_params)\n",
    "_, data, whiten, cnorm = setup_data(p, test_set=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916\n",
      "12900\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print len(data['test_ind'])\n",
    "print len(data['train_ind'])\n",
    "print len(data['valid_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['load_from',\n",
       " 'save_dir',\n",
       " 'zestbn',\n",
       " 'dseed',\n",
       " 'commit',\n",
       " 'top_c',\n",
       " 'act',\n",
       " 'batch_size',\n",
       " 'dataset',\n",
       " 'valid_set_size',\n",
       " 'num_epochs',\n",
       " 'whiten_zca',\n",
       " 'unlabeled_samples',\n",
       " 'decoder_spec',\n",
       " 'denoising_cost_x',\n",
       " 'f_local_noise_std',\n",
       " 'cmd',\n",
       " 'lrate_decay',\n",
       " 'seed',\n",
       " 'lr',\n",
       " 'save_to',\n",
       " 'super_noise_std',\n",
       " 'valid_batch_size',\n",
       " 'contrast_norm',\n",
       " 'encoder_layers',\n",
       " 'labeled_samples']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p.data_type = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ladder = setup_model(p)\n",
    "dset, indices, calc_batchnorm = {\n",
    "        'train': (data.train, data.train_ind, True), ## Changing from False\n",
    "        'valid': (data.valid, data.valid_ind, True),\n",
    "        'test':  (data.test, data.test_ind, True),\n",
    "    }[p.data_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = make_datastream(dset, indices,\n",
    "                         batch_size=p.get('batch_size'),\n",
    "                         n_labeled=len(indices),\n",
    "                         n_unlabeled=len(indices),\n",
    "                         balanced_classes=False,\n",
    "                         whiten=whiten,\n",
    "                         cnorm=cnorm,\n",
    "                         scheme=SequentialScheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SemiDataStream.get_data of <run_emboot.SemiDataStream object at 0x7f2b46666950>>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:main:== COMMAND LINE ==\n",
      "INFO:main:/net/kate/storage/work/ajaynagesh/software/miniconda3/envs/ladder/lib/python2.7/site-packages/ipykernel/__main__.py -f /run/user/21964/jupyter/kernel-c13c0f0e-1b3d-45bb-be8b-b8ba7d053d03.json\n",
      "INFO:main:== PARAMETERS ==\n",
      "INFO:main: load_from           : None                 <- /work/ajaynagesh/LadderNetworks/ladder/results/emboot_100_full0\n",
      "INFO:main: save_dir            : results/emboot_100_full_crtparams20 \n",
      "INFO:main: zestbn              : bugfix               \n",
      "INFO:main: dseed               : 1                    \n",
      "INFO:main: commit              : f0efd0a55a2c419b332c8f730f86bcd5e4330be9 \n",
      "INFO:main: top_c               : 1                    \n",
      "INFO:main: act                 : relu                 \n",
      "INFO:main: batch_size          : 100                  \n",
      "INFO:main: dataset             : emboot               \n",
      "INFO:main: data_type           : None                 <- train\n",
      "INFO:main: valid_set_size      : 10000                \n",
      "INFO:main: num_epochs          : 150                  \n",
      "INFO:main: no_load             : None                 <- g_\n",
      "INFO:main: whiten_zca          : 0                    \n",
      "INFO:main: unlabeled_samples   : 12900                \n",
      "INFO:main: decoder_spec        : ('gauss', 'gauss', 'gauss', 'gauss', 'gauss', 'gauss') \n",
      "INFO:main: denoising_cost_x    : (1000.0, 10.0, 0.1, 0.1, 0.1, 0.1) \n",
      "INFO:main: f_local_noise_std   : (0.30000001, 0.30000001, 0.30000001, 0.30000001, 0.30000001, 0.30000001) \n",
      "INFO:main: cmd                 : train                \n",
      "INFO:main: lrate_decay         : 0.67                 \n",
      "INFO:main: seed                : 1                    \n",
      "INFO:main: lr                  : 0.002                \n",
      "INFO:main: save_to             : emboot_100_full_crtparams2 \n",
      "INFO:main: super_noise_std     : 0.3                  \n",
      "INFO:main: valid_batch_size    : 100                  \n",
      "INFO:main: contrast_norm       : 0                    \n",
      "INFO:main: encoder_layers      : ((600,), '500', '250', '250', '250', '4') \n",
      "INFO:main: labeled_samples     : 100                  \n",
      "INFO:main:Using 100 examples for validation\n",
      "INFO:main.model:Encoder: clean, labeled\n",
      "INFO:main.model:  0: noise 0\n",
      "INFO:main.model:  f1: fc, relu, BN, noise 0.00, params 500, dim (600,) -> (500,)\n",
      "INFO:main.model:  f2: fc, relu, BN, noise 0.00, params 250, dim (500,) -> (250,)\n",
      "INFO:main.model:  f3: fc, relu, BN, noise 0.00, params 250, dim (250,) -> (250,)\n",
      "INFO:main.model:  f4: fc, relu, BN, noise 0.00, params 250, dim (250,) -> (250,)\n",
      "INFO:main.model:  f5: fc, softmax, BN, noise 0.00, params 4, dim (250,) -> (4,)\n",
      "INFO:main.model:Encoder: corr, labeled\n",
      "INFO:main.model:  0: noise 0.3\n",
      "INFO:main.model:  f1: fc, relu, BN, noise 0.30, params 500, dim (600,) -> (500,)\n",
      "INFO:main.model:  f2: fc, relu, BN, noise 0.30, params 250, dim (500,) -> (250,)\n",
      "INFO:main.model:  f3: fc, relu, BN, noise 0.30, params 250, dim (250,) -> (250,)\n",
      "INFO:main.model:  f4: fc, relu, BN, noise 0.30, params 250, dim (250,) -> (250,)\n",
      "INFO:main.model:  f5: fc, softmax, BN, noise 0.30, params 4, dim (250,) -> (4,)\n",
      "INFO:main.model:Decoder: z_corr -> z_est\n",
      "INFO:main.model:  g5:      gauss, denois 0.10, dim None -> (4,)\n",
      "INFO:main.model:  g4:      gauss, denois 0.10, dim (4,) -> (250,)\n",
      "INFO:main.model:  g3:      gauss, denois 0.10, dim (250,) -> (250,)\n",
      "INFO:main.model:  g2:      gauss, denois 0.10, dim (250,) -> (250,)\n",
      "INFO:main.model:  g1:      gauss, denois 10.00, dim (250,) -> (500,)\n",
      "INFO:main.model:  g0:      gauss, denois 1000.00, dim (500,) -> (600,)\n",
      "INFO:main:Loading parameters: g_2_a6, g_2_a7, g_2_a4, g_2_a5, g_2_a2, g_2_a3, g_2_a1, g_0_a4, g_3_a10, g_0_a6, g_0_a7, g_0_W, g_2_a8, g_2_a9, g_4_W, f_3_b, g_1_W, g_0_a8, g_1_a3, f_3_W, g_0_a9, g_5_a7, g_5_a6, g_5_a5, g_5_a4, g_5_a3, g_5_a2, g_5_a1, g_5_a9, g_5_a8, g_1_a1, g_0_a5, g_3_W, f_4_W, g_1_a4, f_5_W, g_1_a10, g_0_a1, g_1_a5, g_1_a2, f_2_W, g_2_W, g_4_a4, g_4_a5, g_0_a10, g_4_a7, g_4_a8, g_4_a9, g_1_a9, g_0_a3, g_5_a10, f_1_W, f_1_b, g_4_a6, g_3_a9, g_3_a8, g_1_a8, g_4_a1, g_3_a5, g_3_a4, g_3_a7, f_2_b, g_3_a1, g_4_a2, g_3_a3, g_3_a2, g_4_a10, g_4_a3, g_2_a10, f_4_b, g_0_a2, g_1_a7, g_3_a6, f_5_b, f_5_c, g_1_a6\n",
      "INFO:main:Calculating batch normalization for clean.labeled path\n",
      "INFO:main:Balancing 100 labels...\n",
      "INFO:main.nn:Batch norm parameters: f_1_bn_mean_clean, f_1_bn_var_clean, f_2_bn_mean_clean, f_2_bn_var_clean, f_3_bn_mean_clean, f_3_bn_var_clean, f_4_bn_mean_clean, f_4_bn_var_clean, f_5_bn_mean_clean, f_5_bn_var_clean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.train_ind [ 209 9577 5670 ..., 5373 2944 9987]\n",
      "data.train_ind (12900,)\n",
      "data - keys ['valid_ind', 'test_ind', 'train_ind', 'train', 'test', 'valid']\n",
      "valid_ind --> SZ: 100\n",
      "test_ind --> SZ: 916\n",
      "train_ind --> SZ: 12900\n",
      "train 13000\n",
      "test 916\n",
      "valid 13000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_1_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_1_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_1_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_1_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_2_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_2_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_2_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_2_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_3_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_3_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_3_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_3_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_4_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_4_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_4_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_4_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_5_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_5_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_5_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_5_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Compiling initialization and readout functions\n",
      "DEBUG:blocks.monitoring.evaluators:Initialization and readout functions compiled\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: cost_class_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for cost_class_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: error_rate_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for error_rate_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois0\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois0\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois1\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois1\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois2\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois2\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois3\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois3\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois4\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois4\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois5\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois5\n",
      "DEBUG:blocks.monitoring.evaluators:Compiling initialization and readout functions\n",
      "DEBUG:blocks.monitoring.evaluators:Initialization and readout functions compiled\n",
      "INFO:main.nn:Batch norm parameters: f_1_bn_mean_clean, f_1_bn_var_clean, f_2_bn_mean_clean, f_2_bn_var_clean, f_3_bn_mean_clean, f_3_bn_var_clean, f_4_bn_mean_clean, f_4_bn_var_clean, f_5_bn_mean_clean, f_5_bn_var_clean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e 0, i 0:VF_C_class 0.815, VF_E 26, VF_C_de 0.00126 0.623 0.981 0.76\n"
     ]
    }
   ],
   "source": [
    "cli_params['data_type'] = 'train'\n",
    "targets, acts = analyze(cli_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reload run_emboot.py with the changed file and also print the batch size\n",
    "\n",
    "However to effective reload , we need to restart the kernel \n",
    "See: https://support.enthought.com/hc/en-us/articles/204469240-Jupyter-IPython-After-editing-a-module-changes-are-not-effective-without-kernel-restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys,os,os.path\n",
    "os.environ['FUEL_DATA_PATH']=\"/work/ajaynagesh/LadderNetworks/ladder/data\"\n",
    "\n",
    "cli_params = dict()\n",
    "cli_params['load_from'] = \"/work/ajaynagesh/LadderNetworks/ladder/results/emboot_100_full0\"\n",
    "cli_params['no_load'] = 'g_'\n",
    "cli_params['data_type'] = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------ Batch Sz = 100 ---------\n",
      "data.train_ind [ 209 9577 5670 ..., 5373 2944 9987]\n",
      "data.train_ind (12900,)\n",
      "data - keys ['valid_ind', 'test_ind', 'train_ind', 'train', 'test', 'valid']\n",
      "valid_ind --> SZ: 100\n",
      "test_ind --> SZ: 916\n",
      "train_ind --> SZ: 12900\n",
      "train 13000\n",
      "test 916\n",
      "valid 13000\n",
      "e 0, i 0:VF_C_class 0.815, VF_E 26, VF_C_de 0.00126 0.623 0.981 0.76\n"
     ]
    }
   ],
   "source": [
    "from run_emboot import *\n",
    "targets, acts = analyze(cli_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "guess = numpy.argmax(acts, axis=1)\n",
    "correct = numpy.sum(numpy.equal(guess, targets.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error on the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.4573643411\n"
     ]
    }
   ],
   "source": [
    "print (1. - correct / float(len(guess))) * 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMBOOT Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuel_converter import EMBOOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emboot_train = EMBOOT(['train'])\n",
    "emboot_test = EMBOOT(['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000\n",
      "916\n"
     ]
    }
   ],
   "source": [
    "print emboot_train.num_examples\n",
    "print emboot_test.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'features': (u'batch', u'feature'), u'targets': (u'batch', u'index')}\n"
     ]
    }
   ],
   "source": [
    "print emboot_train.axis_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[-0.03081121, -0.05515246, -0.00701181, ..., -0.03319645,\n",
      "        -0.00103687, -0.03405993],\n",
      "       [-0.00316652, -0.08585572,  0.00378593, ..., -0.0073941 ,\n",
      "         0.04546531, -0.06978292],\n",
      "       [ 0.04344497, -0.05054203,  0.00522156, ...,  0.04237889,\n",
      "         0.01932781,  0.05354481],\n",
      "       ..., \n",
      "       [-0.01100759,  0.00742121,  0.04095598, ...,  0.02451436,\n",
      "         0.03807044,  0.00670465],\n",
      "       [ 0.02293569, -0.1489239 ,  0.05471994, ...,  0.04448456,\n",
      "         0.06721334,  0.02222161],\n",
      "       [ 0.07164202,  0.02218784,  0.06132978, ...,  0.01108115,\n",
      "         0.07298984,  0.05412074]]), array([[1],\n",
      "       [1],\n",
      "       [2],\n",
      "       ..., \n",
      "       [2],\n",
      "       [0],\n",
      "       [0]], dtype=uint8))\n"
     ]
    }
   ],
   "source": [
    "print emboot_train.data_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuel.datasets import MNIST\n",
    "mnist_train = MNIST(['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ..., \n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ..., \n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ..., \n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        ..., \n",
       "        [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ..., \n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ..., \n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        [[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ..., \n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]]], dtype=float32), array([[5],\n",
       "        [0],\n",
       "        [4],\n",
       "        ..., \n",
       "        [5],\n",
       "        [6],\n",
       "        [8]], dtype=uint8))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.data_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the ladder model trained on MNIST\n",
    "\n",
    "using 100 examples for supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n",
      "INFO:main:== COMMAND LINE ==\n",
      "INFO:main:/net/kate/storage/work/ajaynagesh/software/miniconda3/envs/ladder/lib/python2.7/site-packages/ipykernel/__main__.py -f /run/user/21964/jupyter/kernel-c13c0f0e-1b3d-45bb-be8b-b8ba7d053d03.json\n",
      "INFO:main:== PARAMETERS ==\n",
      "INFO:main: load_from           : None                 <- /work/ajaynagesh/LadderNetworks/ladder.orig/results/mnist_100_full0\n",
      "INFO:main: save_dir            : results/mnist_100_full0 \n",
      "INFO:main: zestbn              : bugfix               \n",
      "INFO:main: dseed               : 1                    \n",
      "INFO:main: commit              : 5a8daa1760535ec4aa25c20c531e1cc31c76d911 \n",
      "INFO:main: top_c               : 1                    \n",
      "INFO:main: act                 : relu                 \n",
      "INFO:main: batch_size          : 100                  \n",
      "INFO:main: dataset             : mnist                \n",
      "INFO:main: data_type           : None                 <- test\n",
      "INFO:main: valid_set_size      : 10000                \n",
      "INFO:main: num_epochs          : 150                  \n",
      "INFO:main: no_load             : None                 <- g_\n",
      "INFO:main: whiten_zca          : 0                    \n",
      "INFO:main: unlabeled_samples   : 60000                \n",
      "INFO:main: decoder_spec        : ('gauss', 'gauss', 'gauss', 'gauss', 'gauss', 'gauss', 'gauss') \n",
      "INFO:main: denoising_cost_x    : (1000.0, 10.0, 0.1, 0.1, 0.1, 0.1, 0.1) \n",
      "INFO:main: f_local_noise_std   : (0.30000001, 0.30000001, 0.30000001, 0.30000001, 0.30000001, 0.30000001, 0.30000001) \n",
      "INFO:main: cmd                 : train                \n",
      "INFO:main: lrate_decay         : 0.67                 \n",
      "INFO:main: seed                : 1                    \n",
      "INFO:main: lr                  : 0.002                \n",
      "INFO:main: save_to             : mnist_100_full       \n",
      "INFO:main: super_noise_std     : 0.3                  \n",
      "INFO:main: valid_batch_size    : 100                  \n",
      "INFO:main: contrast_norm       : 0                    \n",
      "INFO:main: encoder_layers      : ((1, 28, 28), '1000', '500', '250', '250', '250', '10') \n",
      "INFO:main: labeled_samples     : 100                  \n",
      "INFO:main:Using 0 examples for validation\n",
      "INFO:main.model:Encoder: clean, labeled\n",
      "INFO:main.model:  0: noise 0\n",
      "INFO:main.model:  f1: fc, relu, BN, noise 0.00, params 1000, dim (1, 28, 28) -> (1000,)\n",
      "INFO:main.model:  f2: fc, relu, BN, noise 0.00, params 500, dim (1000,) -> (500,)\n",
      "INFO:main.model:  f3: fc, relu, BN, noise 0.00, params 250, dim (500,) -> (250,)\n",
      "INFO:main.model:  f4: fc, relu, BN, noise 0.00, params 250, dim (250,) -> (250,)\n",
      "INFO:main.model:  f5: fc, relu, BN, noise 0.00, params 250, dim (250,) -> (250,)\n",
      "INFO:main.model:  f6: fc, softmax, BN, noise 0.00, params 10, dim (250,) -> (10,)\n",
      "INFO:main.model:Encoder: corr, labeled\n",
      "INFO:main.model:  0: noise 0.3\n",
      "INFO:main.model:  f1: fc, relu, BN, noise 0.30, params 1000, dim (1, 28, 28) -> (1000,)\n",
      "INFO:main.model:  f2: fc, relu, BN, noise 0.30, params 500, dim (1000,) -> (500,)\n",
      "INFO:main.model:  f3: fc, relu, BN, noise 0.30, params 250, dim (500,) -> (250,)\n",
      "INFO:main.model:  f4: fc, relu, BN, noise 0.30, params 250, dim (250,) -> (250,)\n",
      "INFO:main.model:  f5: fc, relu, BN, noise 0.30, params 250, dim (250,) -> (250,)\n",
      "INFO:main.model:  f6: fc, softmax, BN, noise 0.30, params 10, dim (250,) -> (10,)\n",
      "INFO:main.model:Decoder: z_corr -> z_est\n",
      "INFO:main.model:  g6:      gauss, denois 0.10, dim None -> (10,)\n",
      "INFO:main.model:  g5:      gauss, denois 0.10, dim (10,) -> (250,)\n",
      "INFO:main.model:  g4:      gauss, denois 0.10, dim (250,) -> (250,)\n",
      "INFO:main.model:  g3:      gauss, denois 0.10, dim (250,) -> (250,)\n",
      "INFO:main.model:  g2:      gauss, denois 0.10, dim (250,) -> (500,)\n",
      "INFO:main.model:  g1:      gauss, denois 10.00, dim (500,) -> (1000,)\n",
      "INFO:main.model:  g0:      gauss, denois 1000.00, dim (1000,) -> (1, 28, 28)\n",
      "INFO:main:Loading parameters: g_2_a6, g_2_a7, g_2_a4, g_2_a5, g_2_a2, g_2_a3, g_2_a1, g_0_a4, g_0_a5, g_0_a6, g_0_a7, g_0_W, g_2_a8, g_2_a9, g_0_a8, g_0_a9, g_6_a8, g_6_a9, g_6_a2, g_6_a3, g_6_a1, g_6_a6, g_6_a7, g_6_a4, g_6_a5, g_0_a1, g_0_a2, g_0_a3, g_2_a10, g_1_a3, g_1_a2, g_1_a1, g_2_W, g_1_a7, g_1_a6, g_1_a5, g_1_a4, g_1_a9, g_1_a8, g_3_a9, g_3_a8, g_3_a5, g_3_a4, g_3_a7, g_3_a6, g_3_a1, g_3_a3, g_3_a2, g_0_a10, g_3_a10, g_5_a10, f_5_W, g_1_a10, g_4_a1, g_4_a2, g_4_a3, g_4_a4, g_4_a5, g_4_a6, g_4_a7, g_4_a8, g_4_a9, f_3_W, f_3_b, f_5_b, g_1_W, g_4_W, g_5_a7, g_5_a6, g_5_a5, g_5_a4, g_5_a3, g_5_a2, g_5_a1, g_5_W, g_5_a9, g_5_a8, g_3_W, f_4_W, f_6_c, f_6_b, f_1_b, f_2_W, f_1_W, f_2_b, g_6_a10, g_4_a10, f_4_b, f_6_W\n",
      "INFO:main:Calculating batch normalization for clean.labeled path\n",
      "INFO:main:Balancing 100 labels...\n",
      "INFO:main.nn:Batch norm parameters: f_1_bn_mean_clean, f_1_bn_var_clean, f_2_bn_mean_clean, f_2_bn_var_clean, f_3_bn_mean_clean, f_3_bn_var_clean, f_4_bn_mean_clean, f_4_bn_var_clean, f_5_bn_mean_clean, f_5_bn_var_clean, f_6_bn_mean_clean, f_6_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_1_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_1_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_1_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_1_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_2_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_2_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_2_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_2_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_3_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_3_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_3_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_3_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_4_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_4_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_4_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_4_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_5_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_5_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_5_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_5_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_6_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_6_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_6_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_6_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Compiling initialization and readout functions\n",
      "DEBUG:blocks.monitoring.evaluators:Initialization and readout functions compiled\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: cost_class_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for cost_class_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: error_rate_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for error_rate_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois0\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois0\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois1\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois1\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois2\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois3\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois3\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois4\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois4\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois5\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois5\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois6\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois6\n",
      "DEBUG:blocks.monitoring.evaluators:Compiling initialization and readout functions\n",
      "DEBUG:blocks.monitoring.evaluators:Initialization and readout functions compiled\n",
      "INFO:main.nn:Batch norm parameters: f_1_bn_mean_clean, f_1_bn_var_clean, f_2_bn_mean_clean, f_2_bn_var_clean, f_3_bn_mean_clean, f_3_bn_var_clean, f_4_bn_mean_clean, f_4_bn_var_clean, f_5_bn_mean_clean, f_5_bn_var_clean, f_6_bn_mean_clean, f_6_bn_var_clean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e 0, i 0:VF_C_class nan, VF_E nan, VF_C_de nan nan nan nan\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")\n",
    "\n",
    "import sys,os,os.path\n",
    "os.environ['FUEL_DATA_PATH']=\"/work/ajaynagesh/LadderNetworks/ladder/data\"\n",
    "\n",
    "cli_params = dict()\n",
    "cli_params['load_from'] = \"/work/ajaynagesh/LadderNetworks/ladder.orig/results/mnist_100_full0\"\n",
    "cli_params['no_load'] = 'g_'\n",
    "cli_params['data_type'] = 'test'\n",
    "\n",
    "from run import *\n",
    "targets, acts = analyze(cli_params)\n",
    "\n",
    "guess = numpy.argmax(acts, axis=1)\n",
    "correct = numpy.sum(numpy.equal(guess, targets.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.05\n"
     ]
    }
   ],
   "source": [
    "print (1. - correct / float(len(guess))) * 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Emboot dataset with 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla P4 (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "from fuel_converter_new import EMBOOT_NEW\n",
    "import sys,os,os.path\n",
    "os.environ['FUEL_DATA_PATH']=\"/work/ajaynagesh/LadderNetworks/ladder/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emboot_new_train = EMBOOT_NEW(['train'])\n",
    "emboot_new_test = EMBOOT_NEW(['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10400\n",
      "2600\n"
     ]
    }
   ],
   "source": [
    "print emboot_new_train.num_examples\n",
    "print emboot_new_test.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emboot experiments with the 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")\n",
    "\n",
    "import sys,os,os.path\n",
    "os.environ['FUEL_DATA_PATH']=\"/work/ajaynagesh/LadderNetworks/ladder/data\"\n",
    "\n",
    "cli_params = dict()\n",
    "cli_params['load_from'] = \"/work/ajaynagesh/LadderNetworks/ladder/results/emboot_80_20split0\"\n",
    "cli_params['no_load'] = 'g_'\n",
    "cli_params['data_type'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:main:== COMMAND LINE ==\n",
      "INFO:main:/net/kate/storage/work/ajaynagesh/software/miniconda3/envs/ladder/lib/python2.7/site-packages/ipykernel/__main__.py -f /run/user/21964/jupyter/kernel-c13c0f0e-1b3d-45bb-be8b-b8ba7d053d03.json\n",
      "INFO:main:== PARAMETERS ==\n",
      "INFO:main: load_from           : None                 <- /work/ajaynagesh/LadderNetworks/ladder/results/emboot_80_20split0\n",
      "INFO:main: save_dir            : results/emboot_80_20split0 \n",
      "INFO:main: zestbn              : bugfix               \n",
      "INFO:main: dseed               : 1                    \n",
      "INFO:main: commit              : bef5430559b8b0450f95944e60ca648b657686da \n",
      "INFO:main: top_c               : 1                    \n",
      "INFO:main: act                 : relu                 \n",
      "INFO:main: batch_size          : 100                  \n",
      "INFO:main: dataset             : emboot               \n",
      "INFO:main: data_type           : None                 <- test\n",
      "INFO:main: valid_set_size      : 10000                \n",
      "INFO:main: num_epochs          : 150                  \n",
      "INFO:main: no_load             : None                 <- g_\n",
      "INFO:main: whiten_zca          : 0                    \n",
      "INFO:main: unlabeled_samples   : 10400                \n",
      "INFO:main: decoder_spec        : ('gauss', 'gauss', 'gauss', 'gauss', 'gauss', 'gauss') \n",
      "INFO:main: denoising_cost_x    : (1000.0, 10.0, 0.1, 0.1, 0.1, 0.1) \n",
      "INFO:main: f_local_noise_std   : (0.30000001, 0.30000001, 0.30000001, 0.30000001, 0.30000001, 0.30000001) \n",
      "INFO:main: cmd                 : train                \n",
      "INFO:main: lrate_decay         : 0.67                 \n",
      "INFO:main: seed                : 1                    \n",
      "INFO:main: lr                  : 0.002                \n",
      "INFO:main: save_to             : emboot_80_20split    \n",
      "INFO:main: super_noise_std     : 0.3                  \n",
      "INFO:main: valid_batch_size    : 100                  \n",
      "INFO:main: contrast_norm       : 0                    \n",
      "INFO:main: encoder_layers      : ((600,), '500', '250', '250', '250', '4') \n",
      "INFO:main: labeled_samples     : 100                  \n",
      "INFO:main:Using 0 examples for validation\n",
      "INFO:main.model:Encoder: clean, labeled\n",
      "INFO:main.model:  0: noise 0\n",
      "INFO:main.model:  f1: fc, relu, BN, noise 0.00, params 500, dim (600,) -> (500,)\n",
      "INFO:main.model:  f2: fc, relu, BN, noise 0.00, params 250, dim (500,) -> (250,)\n",
      "INFO:main.model:  f3: fc, relu, BN, noise 0.00, params 250, dim (250,) -> (250,)\n",
      "INFO:main.model:  f4: fc, relu, BN, noise 0.00, params 250, dim (250,) -> (250,)\n",
      "INFO:main.model:  f5: fc, softmax, BN, noise 0.00, params 4, dim (250,) -> (4,)\n",
      "INFO:main.model:Encoder: corr, labeled\n",
      "INFO:main.model:  0: noise 0.3\n",
      "INFO:main.model:  f1: fc, relu, BN, noise 0.30, params 500, dim (600,) -> (500,)\n",
      "INFO:main.model:  f2: fc, relu, BN, noise 0.30, params 250, dim (500,) -> (250,)\n",
      "INFO:main.model:  f3: fc, relu, BN, noise 0.30, params 250, dim (250,) -> (250,)\n",
      "INFO:main.model:  f4: fc, relu, BN, noise 0.30, params 250, dim (250,) -> (250,)\n",
      "INFO:main.model:  f5: fc, softmax, BN, noise 0.30, params 4, dim (250,) -> (4,)\n",
      "INFO:main.model:Decoder: z_corr -> z_est\n",
      "INFO:main.model:  g5:      gauss, denois 0.10, dim None -> (4,)\n",
      "INFO:main.model:  g4:      gauss, denois 0.10, dim (4,) -> (250,)\n",
      "INFO:main.model:  g3:      gauss, denois 0.10, dim (250,) -> (250,)\n",
      "INFO:main.model:  g2:      gauss, denois 0.10, dim (250,) -> (250,)\n",
      "INFO:main.model:  g1:      gauss, denois 10.00, dim (250,) -> (500,)\n",
      "INFO:main.model:  g0:      gauss, denois 1000.00, dim (500,) -> (600,)\n",
      "INFO:main:Loading parameters: g_2_a6, g_2_a7, g_2_a4, g_2_a5, g_2_a2, g_2_a3, g_2_a1, g_0_a4, g_3_a10, g_0_a6, g_0_a7, g_0_W, g_2_a8, g_2_a9, g_4_W, f_3_b, g_1_W, g_0_a8, g_1_a3, f_3_W, g_0_a9, g_5_a7, g_5_a6, g_5_a5, g_5_a4, g_5_a3, g_5_a2, g_5_a1, g_5_a9, g_5_a8, g_1_a1, g_0_a5, g_3_W, f_4_W, g_1_a4, f_5_W, g_1_a10, g_0_a1, g_1_a5, g_1_a2, f_2_W, g_2_W, g_4_a4, g_4_a5, g_0_a10, g_4_a7, g_4_a8, g_4_a9, g_1_a9, g_0_a3, g_5_a10, f_1_W, f_1_b, g_4_a6, g_3_a9, g_3_a8, g_1_a8, g_4_a1, g_3_a5, g_3_a4, g_3_a7, f_2_b, g_3_a1, g_4_a2, g_3_a3, g_3_a2, g_4_a10, g_4_a3, g_2_a10, f_4_b, g_0_a2, g_1_a7, g_3_a6, f_5_b, f_5_c, g_1_a6\n",
      "INFO:main:Calculating batch normalization for clean.labeled path\n",
      "INFO:main:Balancing 100 labels...\n",
      "INFO:main.nn:Batch norm parameters: f_1_bn_mean_clean, f_1_bn_var_clean, f_2_bn_mean_clean, f_2_bn_var_clean, f_3_bn_mean_clean, f_3_bn_var_clean, f_4_bn_mean_clean, f_4_bn_var_clean, f_5_bn_mean_clean, f_5_bn_var_clean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------ Batch Sz = 100 ---------\n",
      "data.train_ind [8364 7892 3583 ...,  905 5192  235]\n",
      "data.train_ind (10400,)\n",
      "data - keys ['valid_ind', 'test_ind', 'train_ind', 'train', 'test', 'valid']\n",
      "valid_ind --> SZ: 0\n",
      "test_ind --> SZ: 2600\n",
      "train_ind --> SZ: 10400\n",
      "train 10400\n",
      "test 2600\n",
      "valid 10400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_1_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_1_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_1_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_1_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_2_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_2_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_2_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_2_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_3_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_3_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_3_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_3_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_4_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_4_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_4_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_4_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_5_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_5_bn_mean_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: f_5_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for f_5_bn_var_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Compiling initialization and readout functions\n",
      "DEBUG:blocks.monitoring.evaluators:Initialization and readout functions compiled\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: cost_class_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for cost_class_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: error_rate_clean\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for error_rate_clean\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois0\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois0\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois1\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois1\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois2\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois2\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois3\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois3\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois4\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois4\n",
      "DEBUG:blocks.monitoring.evaluators:variable to evaluate: denois5\n",
      "DEBUG:blocks.monitoring.evaluators:Using the default  (average over minibatches) aggregation scheme for denois5\n",
      "DEBUG:blocks.monitoring.evaluators:Compiling initialization and readout functions\n",
      "DEBUG:blocks.monitoring.evaluators:Initialization and readout functions compiled\n",
      "INFO:main.nn:Batch norm parameters: f_1_bn_mean_clean, f_1_bn_var_clean, f_2_bn_mean_clean, f_2_bn_var_clean, f_3_bn_mean_clean, f_3_bn_var_clean, f_4_bn_mean_clean, f_4_bn_var_clean, f_5_bn_mean_clean, f_5_bn_var_clean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e 0, i 0:VF_C_class nan, VF_E nan, VF_C_de nan nan nan nan\n"
     ]
    }
   ],
   "source": [
    "from run_emboot import *\n",
    "targets, acts = analyze(cli_params)\n",
    "\n",
    "guess = numpy.argmax(acts, axis=1)\n",
    "correct = numpy.sum(numpy.equal(guess, targets.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "This is the test error on Emboot test data\n",
    "\n",
    "Training dataset size: 10400\n",
    "Test dataset size: 2600\n",
    "\n",
    "80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.9230769231\n"
     ]
    }
   ],
   "source": [
    "print (1. - correct / float(len(guess))) * 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error on test = 21.9230769231\n",
    "##### Error on train = 22.663462"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using validation (400 data points) during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error on Test = 22.769231\n",
    "#### Error on Train = 23.050000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only 20 datapoints as supervision\n",
    "\n",
    "directory: results/emboot_80_20_only20_1\n",
    "\n",
    "cmds: \n",
    "\n",
    "THEANO_FLAGS=device=gpu2  python run_emboot.py train --encoder-layers 500-250-250-250-4 --decoder-spec gauss --denoising-cost-x 1000,10,0.1,0.1,0.1,0.1 --labeled-samples 20 --unlabeled-samples 10400 --seed 1 --dataset emboot  -- emboot_80_20_only20_\n",
    "\n",
    " python ./run_emboot.py evaluate  results/emboot_80_20_only20_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test error: 51.730769\n",
    "#### train error: 29.048077"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only 40 datapoints as supervision\n",
    "\n",
    "directory: emboot_80_20_only40_0\n",
    "\n",
    "cmds: \n",
    "\n",
    "\n",
    "THEANO_FLAGS=device=gpu2  python run_emboot.py train --encoder-layers 500-250-250-250-4 --decoder-spec gauss --denoising-cost-x 1000,10,0.1,0.1,0.1,0.1 --labeled-samples 40 --unlabeled-samples 10400 --seed 1 --dataset emboot  -- emboot_80_20_only40_\n",
    "\n",
    "\n",
    "python ./run_emboot.py evaluate  results/emboot_80_20_only40_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test error: 26.923077\n",
    "#### train error: 24.250000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Using only 200 datapoints as supervision\n",
    "\n",
    "directory: emboot_80_20_only200_0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test error:  19.807692\n",
    "#### train error: 20.894231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only 400 datapoints as supervision\n",
    "\n",
    "directory: emboot_80_20_only400_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test error:  18.076923\n",
    "#### train error: 18.942308"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only 800 datapoints as supervision\n",
    "\n",
    "directory: emboot_80_20_only800_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test error:  17.692308\n",
    "#### train error: 17.951923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ladder]",
   "language": "python",
   "name": "conda-env-ladder-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
